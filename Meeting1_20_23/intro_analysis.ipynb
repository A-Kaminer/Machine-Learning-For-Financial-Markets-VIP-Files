{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'patsy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpatsy\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;66;03m#pip install scikit-learn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'patsy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import patsy\n",
    "import sklearn.metrics as metrics #pip install scikit-learn\n",
    "import statsmodels.formula.api as smf\n",
    "#from helper_functions import *\n",
    "from plotnine import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    LogisticRegressionCV,\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "path = \"~/Documents/GeorgiaTech/VIP/VIP-team-Machine-Learning-for-Financial-Markets/data/intro/\"\n",
    "data = pd.read_excel(path+\"ma_data.xlsx\",engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# EDA\n",
    "#\n",
    "data.describe(include = 'all')\n",
    "\n",
    "data['period'] = pd.to_datetime(data['period'], format='%Y/%m/%d')\n",
    "data['event_period'] = pd.to_datetime(data['event_period'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms data.columns.tolist()\n",
    "data[[\"ret\",\"sale\",'prc', 'ret2yr', \n",
    "      'logsize', 'logBM', 'mombcz', 'roa', 'beta', \n",
    "      'dividend', 'irisk', 'illiq', 'turnover', 'leverage', \n",
    "      'salesprice','event_firm', ]].hist(\n",
    "    bins=15,\n",
    "    figsize=(10, 8),\n",
    "    grid = False,\n",
    "    rwidth = 0.9,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show descriptives for event vs non-event firms\n",
    "data.groupby(['event_firm'])['ret','sale','logsize'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns: Box-plot\n",
    "(\n",
    "    ggplot(data, aes(y=\"ret\", x=\"event_firm\", group = \"event_firm\"))\n",
    "    + geom_boxplot(color=\"blue\", size=0.5, width=0.1, alpha=0.5)\n",
    "    + stat_boxplot(geom = \"errorbar\", width = 0.05,  size = 0.5, color = 'red')\n",
    "    + stat_summary(fun_data=\"mean_se\", geom=\"point\", size=4, color=\"red\", fill=\"red\")\n",
    "    + labs(x=\"M&A\", y=\"Return\")\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size: Box-plot\n",
    "( ggplot(data, aes(y=\"logsize\", x=\"event_firm\", group = \"event_firm\"))\n",
    "    + geom_boxplot(color=\"blue\", size=0.5, width=0.1, alpha=0.5)\n",
    "    + stat_boxplot(geom = \"errorbar\", width = 0.05,  size = 0.5, color = 'red')\n",
    "    + stat_summary(fun_data=\"mean_se\", geom=\"point\", size=4, color=\"red\", fill=\"red\")\n",
    "    + labs(x=\"M&A\", y=\"Log Size\")\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to check the short-run differences\n",
    "ma_short = data.loc[data['event_firm'] == 1]\n",
    "ma_short['devent_period'] = ((ma_short['event_period']-ma_short['period'])/np.timedelta64(1,'M'))\n",
    "ma_short['devent_period'] = ma_short['devent_period'].astype(int)\n",
    "ma_short = ma_short.loc[ma_short['devent_period'].isin([-1,1])]\n",
    "\n",
    "ma_short.groupby(['devent_period'])['ret','sale','logsize'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-short strategy in 2016\n",
    "np.mean(ma_short['ret'].loc[ma_short['devent_period']==-1]) - np.mean(ma_short['ret'].loc[ma_short['devent_period']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-plot for making it more complex\n",
    "( ggplot(ma_short, aes(y=\"ret\", x=\"devent_period\", group = \"devent_period\"))\n",
    "    + geom_boxplot(color=\"blue\", size=0.5, width=0.1, alpha=0.5)\n",
    "    + stat_boxplot(geom = \"errorbar\", width = 0.05,  size = 0.5, color = 'red')\n",
    "    + stat_summary(fun_data=\"mean_se\", geom=\"point\", size=4, color=\"red\", fill=\"red\")\n",
    "    + labs(x=\"M&A\", y=\"Return\")\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Modeling\n",
    "\n",
    "# Handling the missing values:\n",
    "# options\n",
    "#   a) remove\n",
    "#   b) impute and flag\n",
    "#\n",
    "# as we would loose many variable we will impute and add flag variables\n",
    "\n",
    "###\n",
    "# Prepare the data\n",
    "features = ['ret','sale','prc','ret2yr','logsize','logBM','mombcz','roa',\n",
    "              'beta','dividend','irisk','illiq','turnover',\n",
    "              'leverage','salesprice']\n",
    "\n",
    "\n",
    "# Assign flag variables and impute with mean\n",
    "for col in features:\n",
    "    #data[col+\"_missing\"] = data[col].isnull()\n",
    "    data[col] = data[col].fillna(data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# STEP 0)\n",
    "# Create train and holdout samples\n",
    "data_train, data_holdout = train_test_split(data, train_size=0.8, random_state=42)\n",
    "\n",
    "print(\"Total\")\n",
    "print(data[\"event_firm\"].value_counts(normalize=True))\n",
    "print(\"Train\")\n",
    "print(data_train[\"event_firm\"].value_counts(normalize=True))\n",
    "print(\"Holdout\")\n",
    "print(data_holdout[\"event_firm\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# GENERAL MODEL SETUP \n",
    "# Specify 5 fold cross-validation method\n",
    "k = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create trainin matrices\n",
    "model_equation = \"event_firm~\" + \"+\".join(features) #.join(model_vars)\n",
    "y_train, X_train = patsy.dmatrices(model_equation, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Simple Linear Probability Model\n",
    "#   without CV\n",
    "LPM_brier = LinearRegression()\n",
    "lpm = LPM_brier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Simple Logit Model with CV\n",
    "LRCV_brier = LogisticRegressionCV(\n",
    "        Cs=10^20,\n",
    "        cv=k,\n",
    "        refit=True,\n",
    "        scoring=\"neg_brier_score\",\n",
    "        solver=\"newton-cg\",\n",
    "        tol=1e-7,\n",
    "        random_state=42 )\n",
    "        \n",
    "logit = LRCV_brier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# LASSO with logit model\n",
    "\n",
    "# Normalise X vars for Lasso\n",
    "normalized_logitvars = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(X_train),\n",
    "    columns=X_train.design_info.column_names,\n",
    ")\n",
    "\n",
    "# Set regularization parameters\n",
    "lambdas = list(10 ** np.arange(-1, -4.01, -1 / 5))\n",
    "n_obs = normalized_logitvars.shape[0] * 4 / 5\n",
    "C_values = [\n",
    "    1 / (l * n_obs) for l in lambdas\n",
    "]  # Cs are the inverse of regularization strength\n",
    "\n",
    "# Initialize and fit Logit Lasso\n",
    "logLasso_brier = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"neg_brier_score\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n",
    "# Estimate\n",
    "lasso = logLasso_brier.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Random Forest\n",
    "#\n",
    "# a) show a single tree\n",
    "#\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Each Random Forest is composed by trees\n",
    "data_for_graph = data_train[[\"ret\", \"logsize\", \"logBM\",\"mombcz\"]]\n",
    "rf_for_graph = DecisionTreeClassifier(\n",
    "    ccp_alpha=0.00005, min_samples_leaf=100, max_depth=5, random_state=41\n",
    ").fit(data_for_graph, y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(11, 11))\n",
    "plot_tree(\n",
    "    rf_for_graph,\n",
    "    feature_names=data_for_graph.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    proportion=True,\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.title(\"Decision tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# b) Do the actual forest\n",
    "grid = {\n",
    "    \"max_features\": [5],\n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"min_samples_split\": [16],\n",
    "} \n",
    "    \n",
    "# 5 fold CV\n",
    "prob_forest = RandomForestClassifier(random_state=42, n_estimators=100, oob_score=True)\n",
    "prob_forest_grid = GridSearchCV(\n",
    "    prob_forest,\n",
    "    grid,\n",
    "    cv=k,\n",
    "    refit=\"roc_auc\",\n",
    "    scoring=[\"roc_auc\"],\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "prob_forest_fit = prob_forest_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Compare predictions\n",
    "_, X_holdout = patsy.dmatrices(model_equation, data_holdout)\n",
    "\n",
    "# Predict on holdut sample\n",
    "data_holdout[\"lpm_pred\"] = lpm.predict(X_holdout)\n",
    "data_holdout[\"logit_pred\"] = logit.predict_proba(X_holdout)[:, 1]\n",
    "data_holdout[\"lasso_pred\"] = lasso.predict_proba(X_holdout)[:, 1]\n",
    "data_holdout[\"rf_pred\"] = prob_forest_fit.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "# Calculate the RMSE\n",
    "print(\"Linear Probability Model\")\n",
    "round(rmse(data_holdout[\"lpm_pred\"], data_holdout[\"event_firm\"]), 4)\n",
    "print(\"Logit Model\")\n",
    "round(rmse(data_holdout[\"logit_pred\"], data_holdout[\"event_firm\"]), 4)\n",
    "print(\"LASSO with Logit\")\n",
    "round(rmse(data_holdout[\"lasso_pred\"], data_holdout[\"event_firm\"]), 4)\n",
    "print(\"Random Forest\")\n",
    "round(rmse(data_holdout[\"rf_pred\"], data_holdout[\"event_firm\"]), 4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
